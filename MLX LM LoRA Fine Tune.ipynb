{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1055c3f3",
   "metadata": {},
   "source": [
    "### LoRA Fine-Tuning with MLX LM\n",
    "\n",
    "In this notebook, we'll walk through how to [LoRA fine-tune](https://arxiv.org/abs/2106.09685) an LLM with MLX LM. We'll use the [HellaSwag](https://rowanzellers.com/hellaswag/) dataset for common sense reasoning as an example. An outline:\n",
    "\n",
    "1. Download the dataset and prepare it in the right format for MLX LM.\n",
    "2. Setup and run LoRA training. We'll show how to capture the training logs and plot some statistics to visualize the performance.\n",
    "3. Evaluate on the test set. We'll compute the final question-answer accuracy of the fine-tuned model.\n",
    "4. Fuse the resulting adapters into the base model and upload to Hugging Face.\n",
    "5. Discuss tips for debugging accuracy and efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21397627",
   "metadata": {},
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "664272fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlx-lm in /Users/dariomelle/anaconda3/envs/gptoss20b-finetuning-mlx/lib/python3.12/site-packages (0.28.0)\n",
      "Requirement already satisfied: mlx>=0.29.1 in /Users/dariomelle/anaconda3/envs/gptoss20b-finetuning-mlx/lib/python3.12/site-packages (from mlx-lm) (0.29.1)\n",
      "Requirement already satisfied: numpy in /Users/dariomelle/anaconda3/envs/gptoss20b-finetuning-mlx/lib/python3.12/site-packages (from mlx-lm) (2.3.3)\n",
      "Requirement already satisfied: transformers>=4.39.3 in /Users/dariomelle/anaconda3/envs/gptoss20b-finetuning-mlx/lib/python3.12/site-packages (from mlx-lm) (4.56.2)\n",
      "Requirement already satisfied: protobuf in /Users/dariomelle/anaconda3/envs/gptoss20b-finetuning-mlx/lib/python3.12/site-packages (from mlx-lm) (6.32.1)\n",
      "Requirement already satisfied: pyyaml in /Users/dariomelle/anaconda3/envs/gptoss20b-finetuning-mlx/lib/python3.12/site-packages (from mlx-lm) (6.0.2)\n",
      "Requirement already satisfied: jinja2 in /Users/dariomelle/anaconda3/envs/gptoss20b-finetuning-mlx/lib/python3.12/site-packages (from mlx-lm) (3.1.6)\n",
      "Requirement already satisfied: mlx-metal==0.29.1 in /Users/dariomelle/anaconda3/envs/gptoss20b-finetuning-mlx/lib/python3.12/site-packages (from mlx>=0.29.1->mlx-lm) (0.29.1)\n",
      "Requirement already satisfied: filelock in /Users/dariomelle/anaconda3/envs/gptoss20b-finetuning-mlx/lib/python3.12/site-packages (from transformers>=4.39.3->mlx-lm) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Users/dariomelle/anaconda3/envs/gptoss20b-finetuning-mlx/lib/python3.12/site-packages (from transformers>=4.39.3->mlx-lm) (0.35.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/dariomelle/anaconda3/envs/gptoss20b-finetuning-mlx/lib/python3.12/site-packages (from transformers>=4.39.3->mlx-lm) (25.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/dariomelle/anaconda3/envs/gptoss20b-finetuning-mlx/lib/python3.12/site-packages (from transformers>=4.39.3->mlx-lm) (2025.9.18)\n",
      "Requirement already satisfied: requests in /Users/dariomelle/anaconda3/envs/gptoss20b-finetuning-mlx/lib/python3.12/site-packages (from transformers>=4.39.3->mlx-lm) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/dariomelle/anaconda3/envs/gptoss20b-finetuning-mlx/lib/python3.12/site-packages (from transformers>=4.39.3->mlx-lm) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/dariomelle/anaconda3/envs/gptoss20b-finetuning-mlx/lib/python3.12/site-packages (from transformers>=4.39.3->mlx-lm) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/dariomelle/anaconda3/envs/gptoss20b-finetuning-mlx/lib/python3.12/site-packages (from transformers>=4.39.3->mlx-lm) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/dariomelle/anaconda3/envs/gptoss20b-finetuning-mlx/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.39.3->mlx-lm) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/dariomelle/anaconda3/envs/gptoss20b-finetuning-mlx/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.39.3->mlx-lm) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/dariomelle/anaconda3/envs/gptoss20b-finetuning-mlx/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.39.3->mlx-lm) (1.1.10)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/dariomelle/anaconda3/envs/gptoss20b-finetuning-mlx/lib/python3.12/site-packages (from jinja2->mlx-lm) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/dariomelle/anaconda3/envs/gptoss20b-finetuning-mlx/lib/python3.12/site-packages (from requests->transformers>=4.39.3->mlx-lm) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/dariomelle/anaconda3/envs/gptoss20b-finetuning-mlx/lib/python3.12/site-packages (from requests->transformers>=4.39.3->mlx-lm) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/dariomelle/anaconda3/envs/gptoss20b-finetuning-mlx/lib/python3.12/site-packages (from requests->transformers>=4.39.3->mlx-lm) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/dariomelle/anaconda3/envs/gptoss20b-finetuning-mlx/lib/python3.12/site-packages (from requests->transformers>=4.39.3->mlx-lm) (2025.8.3)\n",
      "Requirement already satisfied: matplotlib in /Users/dariomelle/anaconda3/envs/gptoss20b-finetuning-mlx/lib/python3.12/site-packages (3.10.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/dariomelle/anaconda3/envs/gptoss20b-finetuning-mlx/lib/python3.12/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/dariomelle/anaconda3/envs/gptoss20b-finetuning-mlx/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/dariomelle/anaconda3/envs/gptoss20b-finetuning-mlx/lib/python3.12/site-packages (from matplotlib) (4.60.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/dariomelle/anaconda3/envs/gptoss20b-finetuning-mlx/lib/python3.12/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in /Users/dariomelle/anaconda3/envs/gptoss20b-finetuning-mlx/lib/python3.12/site-packages (from matplotlib) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/dariomelle/anaconda3/envs/gptoss20b-finetuning-mlx/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /Users/dariomelle/anaconda3/envs/gptoss20b-finetuning-mlx/lib/python3.12/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/dariomelle/anaconda3/envs/gptoss20b-finetuning-mlx/lib/python3.12/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/dariomelle/anaconda3/envs/gptoss20b-finetuning-mlx/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/dariomelle/anaconda3/envs/gptoss20b-finetuning-mlx/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mlx-lm\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd27c693",
   "metadata": {},
   "source": [
    "### Preprocess Data\n",
    "We'll start by downloading an already pre-processed version of the HellaSwag dataset from [LLM-Adapters](https://github.com/AGI-Edgerunners/LLM-Adapters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61698208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HellaSwag stats: 39905 training examples and 10042 test examples.\n",
      "An example:\n",
      "\n",
      "{\n",
      "    \"instruction\": \"Please choose the correct ending to complete the given sentence: Removing ice from car: Then, the man writes over the snow covering the window of a car, and a woman wearing winter clothes smiles. then\\n\\nEnding1: , the man adds wax to the windshield and cuts it. Ending2: , a person board a ski lift, while two men supporting the head of the person wearing winter clothes snow as the we girls sled. Ending3: , the man puts on a christmas coat, knitted with netting. Ending4: , the man continues removing the snow on his car.\\n\\nAnswer format: ending1/ending2/ending3/ending4\",\n",
      "    \"input\": \"\",\n",
      "    \"output\": \"the correct answer is ending4\",\n",
      "    \"answer\": \"ending4\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from urllib import request\n",
    "\n",
    "save_dir = \"/tmp/hellaswag\"\n",
    "\n",
    "def download_and_save(save_dir):\n",
    "    base_url = \"https://raw.githubusercontent.com/AGI-Edgerunners/LLM-Adapters/main/dataset/hellaswag/\"\n",
    "    save_dir = Path(save_dir)\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for name in [\"train.json\", \"test.json\"]:\n",
    "        out_file = save_dir / name\n",
    "        if not out_file.exists():\n",
    "            request.urlretrieve(base_url + name, out_file)\n",
    "\n",
    "def load_json(dataset):\n",
    "    download_and_save(save_dir)\n",
    "    with open(f\"{save_dir}/{dataset}.json\", \"r\") as fid:\n",
    "        return json.load(fid)\n",
    "\n",
    "train_set, test_set = load_json(\"train\"), load_json(\"test\")\n",
    "print(f\"HellaSwag stats: {len(train_set)} training examples and {len(test_set)} test examples.\")\n",
    "print(\"An example:\\n\")\n",
    "print(json.dumps(train_set[0], indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a514d79",
   "metadata": {},
   "source": [
    "Next, let's split the training set into a training and a validation set. We'll pull out a randomly chosen 10% for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b607237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed for reproducibility\n",
    "np.random.seed(43)\n",
    "perm = np.random.permutation(len(train_set))\n",
    "valid_size = int(0.1 * len(train_set))\n",
    "valid_set = [train_set[i] for i in perm[:valid_size]]\n",
    "train_set = [train_set[i] for i in perm[valid_size:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b259eb69",
   "metadata": {},
   "source": [
    "### Fine-Tune\n",
    "\n",
    "For fine-tuning, we'll use Microsoft's [Phi-3 mini](https://huggingface.co/microsoft/Phi-3-mini-4k-instruct). At 3.8 billion parameters, Phi-3 mini is a high-quality model that is also fast to fine-tune on most Apple silicon machines. Also, it has a [permissive MIT License](https://huggingface.co/microsoft/Phi-3-mini-4k-instruct/blob/main/LICENSE).\n",
    "\n",
    "First, import all the packages and functions we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3ff309a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mlx.core as mx\n",
    "import mlx.optimizers as optim\n",
    "from mlx.utils import tree_flatten\n",
    "from mlx_lm import load, generate\n",
    "from mlx_lm.tuner import train, evaluate, TrainingArgs\n",
    "from mlx_lm.tuner.datasets import CompletionsDataset, CacheDataset\n",
    "from mlx_lm.tuner import linear_to_lora_layers\n",
    "import tqdm\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87628d24",
   "metadata": {},
   "source": [
    "Next, setup the LoRA parameters and make the training arguments. See the [training argument class](https://github.com/ml-explore/mlx-examples/blob/81318ad4a8b2ca5fd1431a42db2b0244d16be851/llms/mlx_lm/tuner/trainer.py#L31-L63) for a more detailed list of training parameters. \n",
    "\n",
    "Recall the LoRA update is $W^\\top \\mathbf{x} + c \\cdot \\mathbf{a} \\mathbf{b}^\\top \\mathbf{x}$ where $\\mathbf{a}$ has shape `(D, rank)`.\n",
    "\n",
    "With that in mind, the LoRA parameters to attend to are:\n",
    "- `lora_layers`: The number of Transformer blocks from the top of the model to adapt.\n",
    "- `rank`: The rank of the low-rank adapters. A larger rank implies more adapter parameters per linear layer.\n",
    "- `scale`: This is the constant $c$ that scales the low-rank update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0851dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a directory to save the adapter config and weights\n",
    "adapter_path = Path(\"adapters\")\n",
    "adapter_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "lora_config = {\n",
    " \"num_layers\": 4,\n",
    " \"lora_parameters\": {\n",
    "    \"rank\": 8,\n",
    "    \"scale\": 20.0,\n",
    "    \"dropout\": 0.0,\n",
    "}}\n",
    "\n",
    "# Save the LoRA config to the adapter path\n",
    "with open(adapter_path / \"adapter_config.json\", \"w\") as fid:\n",
    "    json.dump(lora_config, fid, indent=4)    \n",
    "\n",
    "training_args = TrainingArgs(\n",
    "    adapter_file=adapter_path / \"adapters.safetensors\",\n",
    "    iters=200,\n",
    "    steps_per_eval=50,\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fefd19",
   "metadata": {},
   "source": [
    "Next, load the Phi-3 mini model. Note this may take a few minutes to download from Hugging Face if you haven't downloaded it before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb0b16f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05f158ca5d5f4844be9de424da217285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_path = \"mlx-community/gpt-oss-20b-MXFP4-Q4\"\n",
    "model, tokenizer = load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6609c92a",
   "metadata": {},
   "source": [
    "After loading the model, freeze it's parameters so we don't train them. Then convert linear layers to LoRA layers using the MLX LM utility `linear_to_lora_layers`. The adapters in the `LoRA` layers are not frozen, so they will be included in the model's `trainable_parameters`. Check-out the [LoRA layer implementation](https://github.com/ml-explore/mlx-examples/blob/81318ad4a8b2ca5fd1431a42db2b0244d16be851/llms/mlx_lm/tuner/lora.py#L72-L104) to see how it all works.\n",
    "\n",
    "By default, MLX LM only adapts the query, key, and value projection matrices for Phi-3. You can specify the layers to adapt by setting `lora_parameters[\"keys\"]` to a list of layer names. In this case it defaults to `[\"attn.qkv_proj\"]`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50e1ab3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: 331776\n"
     ]
    }
   ],
   "source": [
    "# Freeze the base model\n",
    "model.freeze()\n",
    "\n",
    "# Convert linear layers to lora layers\n",
    "linear_to_lora_layers(model, lora_config[\"num_layers\"], lora_config[\"lora_parameters\"])\n",
    "\n",
    "num_train_params = (\n",
    "    sum(v.size for _, v in tree_flatten(model.trainable_parameters()))\n",
    ")\n",
    "print(f\"Number of trainable parameters: {num_train_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97656ab",
   "metadata": {},
   "source": [
    "The last step before training is to pre-process the data sets. The pre-processing applies a chat-template and special tokens if necessary. It also tokenizes the data and converts the tokens to integer ids. We'll use a `CompletionsDataset` for this example which does the all of that. For more details, see the [documentation on supported formats](https://github.com/ml-explore/mlx-examples/blob/main/llms/mlx_lm/LORA.md#Data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c5add0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the tokenizer to add the eos token id at the end of each example\n",
    "def make_dataset(ds):\n",
    "    return CompletionsDataset(\n",
    "        ds,\n",
    "        tokenizer,\n",
    "        prompt_key=\"instruction\",\n",
    "        completion_key=\"output\",\n",
    "        mask_prompt=False,\n",
    "    )\n",
    "train_set, valid_set = make_dataset(train_set), make_dataset(valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1cb347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Password:sudo: a password is required\n"
     ]
    }
   ],
   "source": [
    "!sysctl iogpu.wired_limit_mb=13500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827d1590",
   "metadata": {},
   "source": [
    "Now we're ready to put it all together and actually train the model. We'll use `Adam` for the optimizer, but you can specify any [optimizer](https://ml-explore.github.io/mlx/build/html/python/optimizers/common_optimizers.html) with any [scheduler](https://ml-explore.github.io/mlx/build/html/python/optimizers/schedulers.html). We also added a custom class to capture the training and validation loss to plot it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "984516d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training..., iters: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating loss...: 100%|███████████████████████████████████████████████████████████████████████████| 25/25 [00:36<00:00,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1: Val loss 5.609, Val took 36.939s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 10: Train loss 4.924, Learning Rate 1.000e-05, It/sec 0.477, Tokens/sec 147.752, Trained Tokens 3097, Peak mem 12.588 GB\n",
      "Iter 20: Train loss 3.718, Learning Rate 1.000e-05, It/sec 0.552, Tokens/sec 145.906, Trained Tokens 5741, Peak mem 12.588 GB\n",
      "Iter 30: Train loss 3.484, Learning Rate 1.000e-05, It/sec 0.475, Tokens/sec 149.664, Trained Tokens 8890, Peak mem 12.588 GB\n",
      "Iter 40: Train loss 3.202, Learning Rate 1.000e-05, It/sec 0.511, Tokens/sec 147.247, Trained Tokens 11774, Peak mem 12.588 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating loss...: 100%|███████████████████████████████████████████████████████████████████████████| 25/25 [00:35<00:00,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 50: Val loss 2.718, Val took 35.477s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 50: Train loss 2.806, Learning Rate 1.000e-05, It/sec 0.519, Tokens/sec 146.496, Trained Tokens 14595, Peak mem 12.588 GB\n",
      "Iter 60: Train loss 2.785, Learning Rate 1.000e-05, It/sec 0.497, Tokens/sec 146.947, Trained Tokens 17554, Peak mem 12.588 GB\n",
      "Iter 70: Train loss 2.563, Learning Rate 1.000e-05, It/sec 0.466, Tokens/sec 150.192, Trained Tokens 20778, Peak mem 12.588 GB\n",
      "Iter 80: Train loss 2.506, Learning Rate 1.000e-05, It/sec 0.492, Tokens/sec 148.703, Trained Tokens 23798, Peak mem 12.588 GB\n",
      "Iter 90: Train loss 2.547, Learning Rate 1.000e-05, It/sec 0.462, Tokens/sec 151.498, Trained Tokens 27080, Peak mem 12.588 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating loss...: 100%|███████████████████████████████████████████████████████████████████████████| 25/25 [00:35<00:00,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 100: Val loss 2.350, Val took 35.154s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 100: Train loss 2.383, Learning Rate 1.000e-05, It/sec 0.506, Tokens/sec 145.435, Trained Tokens 29957, Peak mem 12.588 GB\n",
      "Iter 100: Saved adapter weights to adapters/adapters.safetensors and adapters/0000100_adapters.safetensors.\n",
      "Iter 110: Train loss 2.475, Learning Rate 1.000e-05, It/sec 0.506, Tokens/sec 148.550, Trained Tokens 32894, Peak mem 12.589 GB\n",
      "Iter 120: Train loss 2.312, Learning Rate 1.000e-05, It/sec 0.523, Tokens/sec 144.687, Trained Tokens 35659, Peak mem 12.589 GB\n",
      "Iter 130: Train loss 2.280, Learning Rate 1.000e-05, It/sec 0.484, Tokens/sec 147.428, Trained Tokens 38708, Peak mem 12.620 GB\n",
      "Iter 140: Train loss 2.132, Learning Rate 1.000e-05, It/sec 0.513, Tokens/sec 145.522, Trained Tokens 41543, Peak mem 12.620 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating loss...: 100%|███████████████████████████████████████████████████████████████████████████| 25/25 [00:38<00:00,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 150: Val loss 2.323, Val took 38.248s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 150: Train loss 2.170, Learning Rate 1.000e-05, It/sec 0.562, Tokens/sec 141.908, Trained Tokens 44069, Peak mem 12.620 GB\n",
      "Iter 160: Train loss 2.299, Learning Rate 1.000e-05, It/sec 0.525, Tokens/sec 145.906, Trained Tokens 46850, Peak mem 12.620 GB\n",
      "Iter 170: Train loss 2.333, Learning Rate 1.000e-05, It/sec 0.474, Tokens/sec 150.191, Trained Tokens 50021, Peak mem 12.620 GB\n",
      "Iter 180: Train loss 2.155, Learning Rate 1.000e-05, It/sec 0.502, Tokens/sec 144.921, Trained Tokens 52907, Peak mem 12.668 GB\n",
      "Iter 190: Train loss 1.996, Learning Rate 1.000e-05, It/sec 0.548, Tokens/sec 139.684, Trained Tokens 55458, Peak mem 12.668 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating loss...: 100%|███████████████████████████████████████████████████████████████████████████| 25/25 [00:39<00:00,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 200: Val loss 2.174, Val took 39.464s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 200: Train loss 2.211, Learning Rate 1.000e-05, It/sec 0.477, Tokens/sec 147.855, Trained Tokens 58560, Peak mem 12.668 GB\n",
      "Iter 200: Saved adapter weights to adapters/adapters.safetensors and adapters/0000200_adapters.safetensors.\n",
      "Saved final weights to adapters/adapters.safetensors.\n"
     ]
    }
   ],
   "source": [
    "# Put the model in training mode:\n",
    "model.train()\n",
    "\n",
    "# Make the optimizer:\n",
    "opt = optim.Adam(learning_rate=1e-5)\n",
    "\n",
    "# Make a class to record the training stats:\n",
    "class Metrics:\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    def on_train_loss_report(self, info):\n",
    "        self.train_losses.append((info[\"iteration\"], info[\"train_loss\"]))\n",
    "    def on_val_loss_report(self, info):\n",
    "        self.val_losses.append((info[\"iteration\"], info[\"val_loss\"]))\n",
    "\n",
    "metrics = Metrics()\n",
    "\n",
    "# Train model:\n",
    "train(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    optimizer=opt,\n",
    "    train_dataset=CacheDataset(train_set),\n",
    "    val_dataset=CacheDataset(valid_set),\n",
    "    training_callback=metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d043b8",
   "metadata": {},
   "source": [
    "The adapters are saved every 100 iterations along with the final adapters in `adapters.safetensors`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac329358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000100_adapters.safetensors adapter_config.json\n",
      "0000200_adapters.safetensors adapters.safetensors\n"
     ]
    }
   ],
   "source": [
    "!ls adapters/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7e23ee",
   "metadata": {},
   "source": [
    "Next, let's plot the training and validation losses to see how well the adapters fit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1ffd638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_its, train_losses = zip(*metrics.train_losses)\n",
    "val_its, val_losses = zip(*metrics.val_losses)\n",
    "plt.plot(train_its, train_losses, '-o')\n",
    "plt.plot(val_its, val_losses, '-o')\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['Train', \"Valid\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28f216c",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "\n",
    "The training and validation loss are only part of the story. For HellaSwag, we ultimately care about how good the model is at answering questions. To asses this, let's generate the actual `ending1`, `ending2`, `ending3`, or `ending4` responses with the fine-tuned model and measure the accuracy.\n",
    "\n",
    "First, let's split the last word off of each output in the test set to create a prompt without the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d96e4dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = [(t[\"instruction\"], *t[\"output\"].rsplit(\" \", maxsplit=1)) for t in test_set]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8becd26a",
   "metadata": {},
   "source": [
    "Next, we'll generate the response for each example in the test set and compare it to the ground-truth answer to measure the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b396980a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, tokenizer, num_test):\n",
    "    num_correct = 0\n",
    "    for prompt, completion, answer in tqdm.tqdm(test_set[:num_test]):    \n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "            {\"role\": \"assistant\", \"content\": completion}\n",
    "        ]\n",
    "        tokens = tokenizer.apply_chat_template(messages, continue_final_message=True)\n",
    "        response = generate(model, tokenizer, tokens, max_tokens=2)\n",
    "        num_correct += (response==answer)\n",
    "    return num_correct / num_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4cbc00b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [01:53<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate test accuracy 0.570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Increase this number to use more test examples\n",
    "num_test = 100\n",
    "test_acc = evaluate(model, tokenizer, num_test)\n",
    "print(f\"Approximate test accuracy {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fbba7f",
   "metadata": {},
   "source": [
    "### Fuse Adapters\n",
    "\n",
    "Sometimes its convenient to fuse the adapters into the base model to create a single adapted model. MLX LM has a fuse script just for that.\n",
    "\n",
    "The adapted weights are: $\\tilde{W} = W + c \\cdot \\mathbf{b}^\\top \\mathbf{a}$. Note, this process can be destructive if the inputs are in low precision and they have very different magnitudes. Tuning the `scale` parameter, $c$, prior to fine-tuning can improve the model performance after fusion.\n",
    "\n",
    "To see more options for fusing the model, including how to upload to HuggingFace [check the documentation](https://github.com/ml-explore/mlx-examples/blob/main/llms/mlx_lm/LORA.md#fuse)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37854c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model\n",
      "Fetching 9 files: 100%|███████████████████████| 9/9 [00:00<00:00, 116869.15it/s]\n",
      "README.md: 100%|███████████████████████████████| 838/838 [00:00<00:00, 4.36MB/s]\n"
     ]
    }
   ],
   "source": [
    "!mlx_lm.fuse --model {model_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c349707e",
   "metadata": {},
   "source": [
    "Once the adapters are fused, we can rerun the evaluation using the fused model to make sure it worked. By default the fused model will be saved to `fused_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1c45e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = load(\"fused_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6736533e-b4e0-4941-9101-5314bc913b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [02:01<00:00,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate test accuracy 0.440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_test = 100\n",
    "test_acc = evaluate(model, tokenizer, num_test)\n",
    "print(f\"Approximate test accuracy {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dc7f4c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Troubleshooting\n",
    "\n",
    "#### Results\n",
    "\n",
    "To figure out why your LoRA adapters are not working well it's critical to plot both the trianing loss and validation loss over the duration of fine-tuning. There are really only two cases to consider: underfitting or overfitting. And you can figure out which regime you are in based on the above plot.\n",
    "\n",
    "**Underfitting**: The trianing loss is not low enough and the validation loss closely matches the training loss. You could also measure the accuracy on the training set itself for question-answering style tasks like HellaSwag. If you are in this regime you have a few options to improve the results:\n",
    "\n",
    "- Use more adapters. Increase `lora_layers` or adapt more of the linear layers within a given block by setting `lora_parameters[\"keys\"]`.\n",
    "- Use a higher rank. A higher rank means more parameters per adapter.\n",
    "- If you are using dropout, decrease the droupout rate or turn it off entirely.\n",
    "- Sometimes, underfitting issues are really optimization issues. In these cases it can be helpful to tune the learning rate or learning rate schedule.\n",
    "- If none of the above works, try a bigger model. For example, try Phi-3 medium instead of Phi-3 tiny.\n",
    "\n",
    "**Overfitting**: The trianing loss keeps going down but the validation loss stops going down and even starts to go up. If you are in this regime you also have a few options:\n",
    "\n",
    "- The best thing to do is to use more trianing data if you have it.\n",
    "- Contrary to the underfitting regime decreasing the capacity of the model can help. For example, use fewer adapters, a lower LoRA rank, or a smaller model size.\n",
    "- If you are not using dropout, use it.\n",
    "\n",
    "If you find your adapters work well pre-fusion but stop working post-fusion, try tuning the `scale` parameter, $c$, prior to fine-tuning. Typically the adapters have a smaller magnitude than the weights, so using a larger scale helps.\n",
    "\n",
    "#### Memory Use\n",
    "\n",
    "Fine-tuning a large LM with LoRA requires a machine with a decent amount of memory. Here are some tips to reduce memory use should you need to do so. \n",
    "\n",
    "- Try quantization (QLoRA). You can use QLoRA by generating a quantized model with `mlx_lm.convert` and the `-q` flag or by using an already quantized model from HuggingFace.\n",
    "\n",
    "- Try using a smaller batch size. You can set the `batch_size` parameter in the `TrainingArgs` or pass `--batch-size` if you are using the CLI. The default is 4 so setting this to 2 or 1 will reduce memory consumption. Note, this may slow things down a little..\n",
    "\n",
    "- Reduce the number of layers to fine-tune with by setting `lora_layers` to a smaller value or passing `--lora-layers` if you are using the CLI. The default is `16`, so you can try `8` or `4`. This reduces the amount of memory needed for back propagation. It may also reduce the quality of the fine-tuned model and you may need to compensate with a larger `rank`.\n",
    "\n",
    "- Longer examples require more memory. If it makes sense for your data, one thing you can do is break your examples into smaller sequences when making the `train`, `valid`, and `test` data sets.\n",
    "\n",
    "- Gradient checkpointing lets you trade-off memory use (less) for computation (more) by recomputing instead of storing intermediate values needed by the backward pass. You can use gradient checkpointing by passing `grad_checkpoint=True` to the `TrainingArgs` or the `--grad-checkpoint` flag if using the CLI. Gradient checkpointing will be more helpful for larger batch sizes or sequence lengths with smaller or quantized models.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- To learn more about MLX check-out the [GitHub repo](http://github.com/ml-explore/mlx) and [documentation](https://ml-explore.github.io/mlx/)\n",
    "- For more on MLX LM check-out the [MLX LM documentation](https://github.com/ml-explore/mlx-examples/tree/main/llms#readme).\n",
    "- Check out the other [MLX Examples](https://github.com/ml-explore/mlx-examples/tree/main). These are great as a learning resource or to use as a starting point for a new project.\n",
    "- We also have an example of [LoRA fine-tuning in MLX Swift](https://github.com/ml-explore/mlx-swift-examples/tree/main/Applications/LoRATrainingExample)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
